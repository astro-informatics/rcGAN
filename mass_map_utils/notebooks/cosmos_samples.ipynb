{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook:\n",
    "- Generate samples of the cosmos convergence field\n",
    "- Plot said samples\n",
    "- Compare with DeepPosterior and Kaiser-Squires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir = '/home/jjwhit/rcGAN/'\n",
    "sys.path.append(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "import types\n",
    "import json\n",
    "\n",
    "from data.lightning.MassMappingDataModule import MMDataModule\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from scipy import ndimage\n",
    "from utils.mri.math import tensor_to_complex_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(\n",
    "    data: torch.Tensor,\n",
    "    mean: Union[float, torch.Tensor],\n",
    "    stddev: Union[float, torch.Tensor],\n",
    "    eps: Union[float, torch.Tensor] = 0.0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize the given tensor.\n",
    "\n",
    "    Applies the formula (data - mean) / (stddev + eps).\n",
    "\n",
    "    Args:\n",
    "        data: Input data to be normalized.\n",
    "        mean: Mean value.\n",
    "        stddev: Standard deviation.\n",
    "        eps: Added to stddev to prevent dividing by zero.\n",
    "\n",
    "    Returns:\n",
    "        Normalized tensor.\n",
    "    \"\"\"\n",
    "    return (data - mean) / (stddev + eps)\n",
    "\n",
    "\n",
    "def normalize_instance(\n",
    "    data: torch.Tensor, eps: Union[float, torch.Tensor] = 0.0\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Normalize the given tensor  with instance norm/\n",
    "\n",
    "    Applies the formula (data - mean) / (stddev + eps), where mean and stddev\n",
    "    are computed from the data itself.\n",
    "\n",
    "    Args:\n",
    "        data: Input data to be normalized\n",
    "        eps: Added to stddev to prevent dividing by zero.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Normalized tensor\n",
    "    \"\"\"\n",
    "\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "\n",
    "    return normalize(data, mean, std, eps), mean, std\n",
    "\n",
    "def normalise_complex(\n",
    "    shear: torch.Tensor, #Shape (2, H, W) \n",
    "    mag_mean: float = 0.14049194898307577,\n",
    "    mag_std: float = 0.11606233247891737,\n",
    "    eps: Union[float, torch.Tensor] = 0.0\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    magnitude = torch.abs(torch.complex(shear[0,:,:], shear[1,:,:]))\n",
    "    phase = torch.angle(torch.complex(shear[0,:,:], shear[1,:,:])) #In radians\n",
    "\n",
    "    normal_mag = (magnitude - mag_mean) / (mag_std + eps)\n",
    "    normal_shear = normal_mag * torch.exp(1j*phase)\n",
    "    normal_real = normal_shear.real\n",
    "    normal_imag = normal_shear.imag\n",
    "    return torch.stack((normal_real, normal_imag)), mag_mean, mag_std\n",
    "\n",
    "def unnormalize_complex(\n",
    "    normed_data: torch.Tensor, \n",
    "    mag_mean: float = 0.14049194898307577, \n",
    "    mag_std: float = 0.11606233247891737,\n",
    "):\n",
    "    normed_mag = torch.abs(torch.complex(normed_data[0,:,:], normed_data[1,:,:]))\n",
    "    phase = torch.angle(torch.complex(normed_data[0,:,:], normed_data[1,:,:]))\n",
    "    # mag_data = ((normed_data * mag_std) / torch.exp(1j*phase)) + mag_mean\n",
    "    # unnormed_data_real = mag_data * torch.cos(phase)\n",
    "    # unnormed_data_imag = mag_data * torch.sin(phase)\n",
    "\n",
    "    unnormed_mag = (normed_mag * mag_std) + mag_mean\n",
    "    unnormed_data = unnormed_mag * torch.exp(1j*phase)\n",
    "    unnormed_data_real = unnormed_data.real\n",
    "    unnormed_data_imag = unnormed_data.imag\n",
    "    return torch.stack((unnormed_data_real, unnormed_data_imag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fourier_kernel(N: int) -> np.ndarray:\n",
    "    \"\"\"Computes the Fourier space kernel which represents the mapping between \n",
    "        convergence (kappa) and shear (gamma).\n",
    "\n",
    "    Args:\n",
    "        N (int): x,y dimension of image patch (assumes square images).\n",
    "\n",
    "    Returns:\n",
    "        D (np.ndarray): Fourier space Kaiser-Squires kernel, with shape = [N,N].\n",
    "    \"\"\"\n",
    "    # Generate grid of Fourier domain\n",
    "    kx = np.arange(N).astype(np.float64) - N/2\n",
    "    kx, ky = np.meshgrid(kx, kx)\n",
    "    k = kx**2 + ky**2\n",
    "    # Define Kaiser-Squires kernel\n",
    "    D = np.zeros((N, N), dtype=np.complex128)\n",
    "    #D = np.where(k > 0, ((kx ** 2.0 - ky ** 2.0) + 1j * (2.0 * kx * ky))/k, D)\n",
    "    # Another formulation to avoid divide by zero warning\n",
    "    D[k>0] = (((kx ** 2.0 - ky ** 2.0) + 1j * (2.0 * kx * ky))[k>0]/k[k>0])\n",
    "    # Apply inverse FFT shift \n",
    "    return np.fft.ifftshift(D)\n",
    "\n",
    "def forward_model(kappa: np.ndarray, D: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Applies the forward mapping between convergence and shear through their \n",
    "        relationship in Fourier space.\n",
    "\n",
    "    Args:\n",
    "        kappa (np.ndarray): Convergence field, with shape [N,N].\n",
    "        D (np.ndarray): Fourier space Kaiser-Squires kernel, with shape = [N,N].\n",
    "\n",
    "    Returns:\n",
    "        gamma (np.ndarray): Shearing field, with shape [N,N].\n",
    "    \"\"\"\n",
    "    F_kappa = np.fft.fft2(kappa) # Perform 2D forward FFT\n",
    "    F_gamma = F_kappa * D # Map convergence onto shear\n",
    "    return np.fft.ifft2(F_gamma) # Perform 2D inverse FFT\n",
    "def realistic_noise_maker(kappa: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Adds realistic simulated Gaussian noise to a mock weak lensing map.\n",
    "\n",
    "    Args:\n",
    "        im_size (int): Size of weak lensing map, in pixels.\n",
    "        kappa (np.ndarray): Convergence map.\n",
    "    \n",
    "    Returns:\n",
    "        gamma (np.ndarray): A synthetic representation of the shear field, gamma, with added noise.\n",
    "    \"\"\"\n",
    "    im_size=300\n",
    "    D = compute_fourier_kernel(im_size) #Fourier kernel\n",
    "    gamma = forward_model(kappa, D) + (\n",
    "        std1 * np.random.randn(im_size, im_size) \n",
    "        + 1.j * std2 * np.random.randn(im_size, im_size)\n",
    "    )\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the cosmos shear, and components needed to generate a mock shear map (model works best with a batch size >1 so we will generate a second map to pass through the model.)\n",
    "mask = np.load('/home/jjwhit/rcGAN/mass_map_utils/cosmos/cosmos_mask.npy', allow_pickle=True)\n",
    "std1 = np.load('/home/jjwhit/rcGAN/mass_map_utils/cosmos/cosmos_std1.npy', allow_pickle=True)\n",
    "std2 = np.load('/home/jjwhit/rcGAN/mass_map_utils/cosmos/cosmos_std2.npy', allow_pickle=True)\n",
    "test_tensor_1 = np.load('/home/jjwhit/rcGAN/mass_map_utils/cosmos/cosmos_shear_cropped.npy', allow_pickle=True)\n",
    "test_tensor_2 = np.load('/share/gpu0/jjwhit/kappa_cosmos_simulations/cropped_dataset/kappa_val/cropped_sim_08985.npy', allow_pickle=True)\n",
    "kappa_mean = 0.00015744006243248638\n",
    "kappa_std  = 0.02968584954283938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be complex64\n",
    "test_tensor_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns the mock convergence map into a mock shear map\n",
    "test_tensor_2 = realistic_noise_maker(test_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the mock map is comparable to the cosmos shear map\n",
    "plt.imshow(test_tensor_1.real)\n",
    "plt.colorbar()\n",
    "plt.title('cosmos shear')\n",
    "plt.show()\n",
    "plt.imshow(test_tensor_2.real)\n",
    "plt.colorbar()\n",
    "plt.title('simulated shear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = np.stack((test_tensor_1, test_tensor_2), axis=0)\n",
    "test_tensor = np.stack((test_tensor.real, test_tensor.imag), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting (2,300,300,2)\n",
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(test_tensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_gamma, mean, std = normalise_complex(test_tensor)\n",
    "normalised_gamma[:, mask==0] = 0\n",
    "normalised_gamma = normalised_gamma.permute(0,3,1,2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting [2, 2, 300, 300]\n",
    "normalised_gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data prep done, will now pass through the GAN to generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(dct):\n",
    "    return types.SimpleNamespace(**dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "with open(dir+'configs/mass_map.yml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    cfg = json.loads(json.dumps(cfg), object_hook=load_object)\n",
    "\n",
    "dm = MMDataModule(cfg)\n",
    "fig_count = 1\n",
    "dm.setup()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "with torch.no_grad():\n",
    "    mmGAN_model = mmGAN.load_from_checkpoint(\n",
    "        checkpoint_path='/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=98.ckpt') \n",
    "        # Currently manually loading desired epoch rather than 'best' epoch\n",
    "\n",
    "    mmGAN_model.cuda()\n",
    "\n",
    "    mmGAN_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens_mmGAN = torch.zeros(size=(2,32, 300,300, 2)).cuda()\n",
    "with torch.no_grad():\n",
    "    print(mmGAN_model.forward(normalised_gamma).shape)\n",
    "    for z in range(32):\n",
    "        gens_mmGAN[:,z, :, :, :] = mmGAN_model.reformat(mmGAN_model.forward(normalised_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting [2, 32, 300, 300, 2]\n",
    "gens_mmGAN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mmGAN = torch.mean(gens_mmGAN, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formats the samples, reconstruction, and standard deviation\n",
    "\n",
    "np_avgs_sim = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "np_samps_sim = {\n",
    "    'mmGAN': [],\n",
    "}\n",
    "\n",
    "np_stds_sim = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "\n",
    "np_avgs_sim['mmGAN'] = ndimage.rotate(\n",
    "    torch.tensor(tensor_to_complex_np((avg_mmGAN[1] * kappa_std + kappa_mean).cpu())).numpy(),\n",
    "    180)\n",
    "for z in range(32):\n",
    "    np_samps_sim['mmGAN'].append(ndimage.rotate(torch.tensor(\n",
    "        tensor_to_complex_np((gens_mmGAN[1, z] * kappa_std + kappa_mean).cpu())).numpy(), 180))\n",
    "\n",
    "np_stds_sim['mmGAN'] = np.std(np.stack(np_samps_sim['mmGAN']), axis=0)\n",
    "\n",
    "np_avgs_cos = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "np_samps_cos = {\n",
    "    'mmGAN': [],\n",
    "}\n",
    "\n",
    "np_stds_cos = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "\n",
    "np_avgs_cos['mmGAN'] = ndimage.rotate(\n",
    "    torch.tensor(tensor_to_complex_np((avg_mmGAN[0] * kappa_std + kappa_mean).cpu())).numpy(),\n",
    "    180)\n",
    "for z in range(32):\n",
    "    np_samps_cos['mmGAN'].append(ndimage.rotate(torch.tensor(\n",
    "        tensor_to_complex_np((gens_mmGAN[0, z] * kappa_std + kappa_mean).cpu())).numpy(), 180))\n",
    "\n",
    "np_stds_cos['mmGAN'] = np.std(np.stack(np_samps_cos['mmGAN']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/share/gpu0/jjwhit/samples/np_avgs_cos.npy', np_avgs_cos['mmGAN'])\n",
    "# np.save('/share/gpu0/jjwhit/samples/np_stds_cos.npy', np_stds_cos['mmGAN'])\n",
    "# np.save('/share/gpu0/jjwhit/samples/np_samps_cos.npy', np_samps_cos['mmGAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip these imports you've run the above cells - these are repeats\n",
    "import sys\n",
    "dir = '/home/jjwhit/rcGAN/'\n",
    "sys.path.append(dir)\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import types\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from data.lightning.MassMappingDataModule import MMDataModule\n",
    "from data.lightning.MassMappingDataModule import MMDataTransform \n",
    "from mass_map_utils.scripts.ks_utils import backward_model\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from utils.mri.math import tensor_to_complex_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not repeats\n",
    "import matplotlib.patches as patches\n",
    "from utils.mri import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as tkr\n",
    "from skimage.measure import find_contours\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from astropy.io import fits\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from lenspack.geometry.projections import gnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also skip these cells if you've run the previous section, skip to the next cell without the 'repeat' comment\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat\n",
    "def load_object(dct):\n",
    "    return types.SimpleNamespace(**dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "with open(dir+'configs/mass_map.yml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    cfg = json.loads(json.dumps(cfg), object_hook=load_object)\n",
    "\n",
    "dm = MMDataModule(cfg)\n",
    "fig_count = 1\n",
    "dm.setup()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "with torch.no_grad():\n",
    "    mmGAN_model = mmGAN.load_from_checkpoint( \n",
    "        checkpoint_path='/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=98.ckpt')\n",
    "    # Manualling loading desired checkpoint, usually is set to best epoch.\n",
    "\n",
    "    mmGAN_model.cuda()\n",
    "\n",
    "    mmGAN_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up edges of COSMOS survey\n",
    "COSMOS_VERTICES = [(149.508, 2.880),\n",
    "                   (149.767, 2.836),\n",
    "                   (149.780, 2.887),\n",
    "                   (150.040, 2.842),\n",
    "                   (150.051, 2.893),\n",
    "                   (150.363, 2.840),\n",
    "                   (150.376, 2.890),\n",
    "                   (150.746, 2.826),\n",
    "                   (150.737, 2.774),\n",
    "                   (150.790, 2.765),\n",
    "                   (150.734, 2.449),\n",
    "                   (150.787, 2.441),\n",
    "                   (150.730, 2.125),\n",
    "                   (150.785, 2.118),\n",
    "                   (150.758, 2.013),\n",
    "                   (150.768, 2.010),\n",
    "                   (150.747, 1.910),\n",
    "                   (150.799, 1.897),\n",
    "                   (150.740, 1.580),\n",
    "                   (150.481, 1.625),\n",
    "                   (150.466, 1.572),\n",
    "                   (150.211, 1.619),\n",
    "                   (150.196, 1.567),\n",
    "                   (149.887, 1.621),\n",
    "                   (149.872, 1.571),\n",
    "                   (149.617, 1.615),\n",
    "                   (149.602, 1.566),\n",
    "                   (149.493, 1.584),\n",
    "                   (149.504, 1.637),\n",
    "                   (149.450, 1.646),\n",
    "                   (149.488, 1.855),\n",
    "                   (149.433, 1.862),\n",
    "                   (149.491, 2.178),\n",
    "                   (149.436, 2.186),\n",
    "                   (149.484, 2.445),\n",
    "                   (149.431, 2.455),\n",
    "                   (149.508, 2.880)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can plot in terms of position on the sky\n",
    "def get_extend_radec(res, width):\n",
    "    ra0, dec0 = (150.11, 2.24) # from cosmos.astro.caltech.edu (could also just use the medians of positions)\n",
    "    proj = gnom.projector(ra0, dec0)\n",
    "    pix_size = res #arcmin\n",
    "    dx = np.deg2rad(width*pix_size/60./2) # number of degrees across\n",
    "    dy = dx\n",
    "    extent_xy = [-dx, dx, -dy, dy]\n",
    "    ra_min, dec_min = proj.xy2radec(-dx, -dy)\n",
    "    ra_max, dec_max = proj.xy2radec(dx, dy)\n",
    "    extent_radec = [ra_min, ra_max, dec_min, dec_max]\n",
    "    return extent_radec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you've run the previous section\n",
    "np_avgs = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "np_samps = {\n",
    "    'mmGAN': [],\n",
    "}\n",
    "\n",
    "np_stds = {\n",
    "    'mmGAN': None,\n",
    "}\n",
    "\n",
    "np_avgs['mmGAN'] = np.load('/share/gpu0/jjwhit/samples/np_avgs_cos.npy')\n",
    "np_stds['mmGAN'] = np.load('/share/gpu0/jjwhit/samples/np_stds_cos.npy')\n",
    "np_samps['mmGAN'] = np.load('/share/gpu0/jjwhit/samples/np_samps_cos.npy')\n",
    "\n",
    "mask = np.load('/home/jjwhit/rcGAN/mass_map_utils/cosmos/cosmos_mask.npy', allow_pickle=True)\n",
    "std1 = np.load(\n",
    "    cfg.cosmo_dir_path + 'cosmos_std1.npy', allow_pickle=True\n",
    ")\n",
    "std2 = np.load(\n",
    "    cfg.cosmo_dir_path + 'cosmos_std2.npy', allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'mmGAN'\n",
    "contours = find_contours(mask, 0.5)\n",
    "outer_contour = max(contours, key=lambda x: x.shape[0])\n",
    "width = 300\n",
    "resolution = 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSMOS reconstruction plus standard deviation, overlayed with xray data\n",
    "\n",
    "\n",
    "nrow = 1\n",
    "ncol = 2\n",
    "width = 300\n",
    "resolution = 0.29\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(8,5), constrained_layout=True)\n",
    "\n",
    "ra, dec = np.array(COSMOS_VERTICES).T\n",
    "axes[0].plot(ra,dec,c='w',lw=1)\n",
    "\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "rotated_img = np.flipud(rotated_img)\n",
    "im1 = axes[0].imshow(rotated_img.real, cmap='magma', vmin=np.min(rotated_img.real), vmax=np.max(np_avgs[method].real),\n",
    "                     origin='lower',extent=get_extend_radec(resolution,  width), aspect='auto')\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_title('COSMOS Reconstruction')\n",
    "axes[0].set_xlabel('Right Ascension')\n",
    "axes[0].set_ylabel('Declination')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "plt.colorbar(im1, ax=axes[0], shrink=1, orientation='horizontal',format=tkr.FormatStrFormatter('%.2f'))\n",
    "\n",
    "highz = (xclusters[:, 6] >= zmin) & (xclusters[:, 6] <= zmax)\n",
    "for cluster in xclusters[highz]:\n",
    "    ra_cl, dec_cl, z_cl = cluster[1], cluster[2], cluster[6]\n",
    "    m500 = cluster[7]\n",
    "    if m500 > m500min:\n",
    "        axes[0].scatter(ra_cl, dec_cl, c='w', s=3)\n",
    "        axes[0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=8, c='w')\n",
    "\n",
    "\n",
    "axes[1].plot(ra,dec,c='w',lw=1)\n",
    "rotated_sd = ndimage.rotate(np_stds[method].real, 270)\n",
    "rotated_sd = np.flipud(rotated_sd)\n",
    "im3 = axes[1].imshow(rotated_sd, cmap='viridis', vmin=0, vmax=np.max(np_stds['mmGAN']), origin='lower',\n",
    "                     extent=get_extend_radec(resolution,  width), aspect='auto')\n",
    "axes[1].invert_xaxis()\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_title('Standard Deviation')\n",
    "axes[1].set_xlabel('Right Ascension')\n",
    "axes[1].set_ylabel('Declination')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "plt.colorbar(im3, ax=axes[1], shrink=1, orientation='horizontal', format=tkr.FormatStrFormatter('%.2f'))\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(f'/share/gpu0/jjwhit/plots/final_2/cosmos_results.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DeepPosterior cosmos reconstruction\n",
    "cosmos_dlp = fits.getdata('/share/gpu0/jjwhit/remy2022_results/cosmos/dlp_cosmos_mean_hdu.fits')\n",
    "start_row = (cosmos_dlp.shape[0] - 300) // 2\n",
    "start_col = (cosmos_dlp.shape[1] - 300) // 2\n",
    "\n",
    "# Extract the center 300x300 portion to match with out reconstruction size\n",
    "cosmos_dlp_resized = cosmos_dlp[start_row:start_row + 300, start_col:start_col + 300]\n",
    "\n",
    "# Cosmos mean/UQ\n",
    "cosmos_samps_dlp = fits.getdata('/share/gpu0/jjwhit/remy2022_results/cosmos/dlp_cosmos_samples_hdu.fits')\n",
    "dlp_std = cosmos_samps_dlp[:,...].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Kaiser-Squires reconstruction\n",
    "\n",
    "D = MMDataTransform.compute_fourier_kernel(cfg.im_size)\n",
    "cropped_cosmos_shear = np.load(dir+'mass_map_utils/cosmos/cosmos_shear_cropped.npy', allow_pickle=True)\n",
    "cropped_kernel = MMDataTransform.compute_fourier_kernel(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min(np_avgs[method].real)\n",
    "vmax = np.max(np_avgs[method].real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 1\n",
    "ncol = 3\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(9,3), constrained_layout=True)\n",
    "\n",
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "\n",
    "axes[0].plot(ra,dec,c='w',lw=1)\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "im1 = axes[0].imshow(rotated_img.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                     extent=get_extend_radec(resolution,  width), aspect='auto')\n",
    "#axes[0].plot(outer_contour[:, 1], outer_contour[:, 0], color='white', linewidth=0.75)\n",
    "axes[0].set_title('GAN (Ours)')\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('Right Ascension')\n",
    "axes[0].set_ylabel('Declination')\n",
    "#m500min=3\n",
    "#zmin=0.1\n",
    "#zmax=0.99\n",
    "#highz = (xclusters[:, 6] >= zmin) & (xclusters[:, 6] <= zmax)\n",
    "#for cluster in xclusters[highz]:\n",
    "#    ra_cl, dec_cl, z_cl = cluster[1], cluster[2], cluster[6]\n",
    "#    m500 = cluster[7]\n",
    "#    if m500 > m500min:\n",
    "#        axes[0].scatter(ra_cl, dec_cl, c='w', s=12)\n",
    "#        axes[0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=8, c='w')\n",
    "\n",
    "axes[1].plot(ra,dec,c='w',lw=1)\n",
    "flipped_img = np.flipud(cosmos_dlp_resized)\n",
    "im3 = axes[1].imshow(flipped_img, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                    extent=get_extend_radec(resolution,  width), aspect='auto')\n",
    "#axes[1].plot(outer_contour[:, 1], outer_contour[:, 0], color='white', linewidth=1)\n",
    "axes[1].set_title('Remy et al.')\n",
    "axes[1].invert_xaxis()\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel('Right Ascension')\n",
    "# axes[1].set_ylabel('Declination')\n",
    "#highz = (xclusters[:, 6] >= zmin) & (xclusters[:, 6] <= zmax)\n",
    "#for cluster in xclusters[highz]:\n",
    "#    ra_cl, dec_cl, z_cl = cluster[1], cluster[2], cluster[6]\n",
    "#    m500 = cluster[7]\n",
    "#    if m500 > m500min:\n",
    "#        axes[1].scatter(ra_cl, dec_cl, c='w', s=12)\n",
    "#        axes[1].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=8, c='w')\n",
    "\n",
    "\n",
    "cosmos_ks = backward_model(cropped_cosmos_shear, cropped_kernel)\n",
    "cosmos_smoothed = np.flipud(ndimage.gaussian_filter(cosmos_ks, sigma=1/.29))\n",
    "\n",
    "axes[2].plot(ra,dec,c='w',lw=1)\n",
    "im4 = axes[2].imshow(cosmos_smoothed.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                    extent=get_extend_radec(resolution,  width), aspect='auto') #TODO: Temp\n",
    "#axes[2].plot(outer_contour[:, 1], outer_contour[:, 0], color='white', linewidth=1)\n",
    "axes[2].set_title('Kaiser-Squires')\n",
    "axes[2].invert_xaxis()\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].set_xlabel('Right Ascension')\n",
    "# axes[2].set_ylabel('Declination')\n",
    "\n",
    "# cbar1 = fig.colorbar(im1, ax=axes[0], orientation='vertical', pad=0.015, shrink=0.8,\n",
    "#                      format=tkr.FormatStrFormatter('%.2f'))\n",
    "# cbar1.mappable.set_clim(vmin, vmax)\n",
    "# cbar2 = fig.colorbar(im3, ax=axes[1], orientation='vertical', pad=0.015, shrink=0.8, \n",
    "#                      format=tkr.FormatStrFormatter('%.2f'))\n",
    "# cbar2.mappable.set_clim()\n",
    "cbar3 = fig.colorbar(im4, ax=axes[2], orientation='vertical', pad=0.015, shrink=0.84, \n",
    "                     format=tkr.FormatStrFormatter('%.2f'))\n",
    "cbar3.mappable.set_clim()\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].set_xticks(x_ticks)\n",
    "    axes[i].set_yticks(y_ticks)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('/share/gpu0/jjwhit/plots/final/cosmos_comparison.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main horizontal plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7), constrained_layout=True)\n",
    "\n",
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "axes[0, 0].plot(ra, dec, c='w', lw=1)\n",
    "im1 = axes[0, 0].imshow(rotated_img.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 0].set_title('GAN (Ours)')\n",
    "axes[0, 0].invert_xaxis()\n",
    "axes[0, 0].set_aspect('equal')\n",
    "axes[0, 0].set_ylabel('Declination')\n",
    "axes[0, 0].set_xlabel('Right Ascension')\n",
    "\n",
    "# Plot 2: Deep Posterior\n",
    "axes[0, 1].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(cosmos_dlp_resized)\n",
    "im2 = axes[0, 1].imshow(flipped_img, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 1].set_title('Remy et al.')\n",
    "axes[0, 1].invert_xaxis()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "axes[0, 1].set_ylabel('Declination')\n",
    "axes[0, 1].set_xlabel('Right Ascension')\n",
    "\n",
    "# Plot 3: Kaiser-Squires\n",
    "axes[0, 2].plot(ra, dec, c='w', lw=1)\n",
    "cosmos_ks = backward_model(cropped_cosmos_shear, cropped_kernel)\n",
    "cosmos_smoothed = np.flipud(ndimage.gaussian_filter(cosmos_ks, sigma=1/.29))\n",
    "im3 = axes[0, 2].imshow(cosmos_smoothed.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 2].set_title('Kaiser-Squires')\n",
    "axes[0, 2].invert_xaxis()\n",
    "axes[0, 2].set_aspect('equal')\n",
    "axes[0, 2].set_xlabel('Right Ascension')\n",
    "axes[0, 2].set_ylabel('Declination')\n",
    "\n",
    "# Plot 4: GAN Uncertainty\n",
    "axes[1, 0].plot(ra, dec, c='w', lw=1)\n",
    "rotated_img = ndimage.rotate(np_stds[method], 270)\n",
    "im4 = axes[1, 0].imshow(rotated_img.real, cmap='viridis', vmin=np.min(np_stds[method]), vmax=np.max(np_stds[method]),\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 0].set_title('GAN Uncertainty (Ours)')\n",
    "axes[1, 0].invert_xaxis()\n",
    "axes[1, 0].set_aspect('equal')\n",
    "axes[1, 0].set_xlabel('Right Ascension')\n",
    "axes[1, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 5: Deep Posterior Uncertainty\n",
    "axes[1, 1].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(dlp_std[30:330, 30:330])\n",
    "im5 = axes[1, 1].imshow(flipped_img, cmap='viridis',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 1].set_title('Remy et al. Uncertainty')\n",
    "axes[1, 1].invert_xaxis()\n",
    "axes[1, 1].set_aspect('equal')\n",
    "axes[1, 1].set_xlabel('Right Ascension')\n",
    "axes[1, 1].set_ylabel('Declination')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "divider1 = make_axes_locatable(axes[0, 0])\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar1 = fig.colorbar(im1, cax=cax1)\n",
    "divider2 = make_axes_locatable(axes[0, 1])\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar2 = fig.colorbar(im2, cax=cax2)\n",
    "divider3 = make_axes_locatable(axes[0, 2])\n",
    "cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar3 = fig.colorbar(im3, cax=cax3)\n",
    "divider4 = make_axes_locatable(axes[1, 0])\n",
    "cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar4 = fig.colorbar(im4, cax=cax4)\n",
    "divider5 = make_axes_locatable(axes[1,1])\n",
    "cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar5 = fig.colorbar(im5, cax=cax5)\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        \n",
    "plt.show()\n",
    "# plt.savefig('/share/gpu0/jjwhit/plots/final_2/cosmos_uq_horizontal.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main vertical plot\n",
    "fig, axes = plt.subplots(3, 2, figsize=(6, 9.7), constrained_layout=True)\n",
    "\n",
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "axes[0, 0].plot(ra, dec, c='w', lw=1)\n",
    "im1 = axes[0, 0].imshow(rotated_img.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 0].set_title('GAN (Ours)')\n",
    "axes[0, 0].invert_xaxis()\n",
    "axes[0, 0].set_aspect('equal')\n",
    "axes[0, 0].set_ylabel('Declination')\n",
    "axes[0, 0].set_xlabel('Right Ascension')\n",
    "\n",
    "# Plot 2: Deep Posterior\n",
    "axes[1, 0].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(cosmos_dlp_resized)\n",
    "im2 = axes[1, 0].imshow(flipped_img, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 0].set_title('Remy et al.')\n",
    "axes[1, 0].invert_xaxis()\n",
    "axes[1, 0].set_aspect('equal')\n",
    "# axes[1, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 3: Kaiser-Squires\n",
    "axes[2, 0].plot(ra, dec, c='w', lw=1)\n",
    "cosmos_ks = backward_model(cropped_cosmos_shear, cropped_kernel)\n",
    "cosmos_smoothed = np.flipud(ndimage.gaussian_filter(cosmos_ks, sigma=1/.29))\n",
    "im3 = axes[2, 0].imshow(cosmos_smoothed.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[2, 0].set_title('Kaiser-Squires')\n",
    "axes[2, 0].invert_xaxis()\n",
    "axes[2, 0].set_aspect('equal')\n",
    "# axes[2, 0].set_xlabel('Right Ascension')\n",
    "# axes[2, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 4: GAN Uncertainty\n",
    "axes[0, 1].plot(ra, dec, c='w', lw=1)\n",
    "rotated_img = ndimage.rotate(np_stds[method], 270)\n",
    "im4 = axes[0, 1].imshow(rotated_img.real, cmap='viridis', vmin=np.min(np_stds[method]), vmax=np.max(np_stds[method]),\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 1].set_title('GAN Uncertainty (Ours)')\n",
    "axes[0, 1].invert_xaxis()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "# axes[0, 1].set_xlabel('Right Ascension')\n",
    "# axes[0, 1].set_ylabel('Declination')\n",
    "\n",
    "# Plot 5: Deep Posterior Uncertainty\n",
    "axes[1, 1].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(dlp_std[30:330, 30:330])\n",
    "im5 = axes[1, 1].imshow(flipped_img, cmap='viridis',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 1].set_title('Remy et al. Uncertainty')\n",
    "axes[1, 1].invert_xaxis()\n",
    "axes[1, 1].set_aspect('equal')\n",
    "# axes[1, 1].set_xlabel('Right Ascension')\n",
    "\n",
    "axes[2, 1].axis('off')\n",
    "\n",
    "cax3 = fig.add_axes([0.08, 0, 0.41, 0.0125]) \n",
    "cbar3 = fig.colorbar(im3, ax=axes[2,0], orientation='horizontal', cax=cax3)\n",
    "cbar3.set_ticks([-0.04, 0.02, 0.08, 0.14])\n",
    "cax4 = fig.add_axes([0.56, 0.67, 0.41, 0.0125]) \n",
    "cbar4 = fig.colorbar(im4, ax=axes[0,1], orientation='horizontal', cax=cax4)\n",
    "cbar4.set_ticks([0.02, 0.06, 0.1, 0.14, 0.18])\n",
    "cax5 = fig.add_axes([0.56, 0.32, 0.41, 0.0125])\n",
    "cbar5 = fig.colorbar(im5, ax=axes[1,1], orientation='horizontal', cax=cax5)\n",
    "cbar5.set_ticks([0.01, 0.03, 0.05, 0.07])\n",
    "\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        \n",
    "plt.show()\n",
    "# plt.savefig('/share/gpu0/jjwhit/plots/final_2/cosmos_uq_comparison_contoured.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the relative uncertainty between the GAN reconstruction and the Remy reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ndimage.rotate(np_avgs[method], 270).real - np.flipud(cosmos_dlp_resized)\n",
    "denom = np.sqrt((np.flipud(ndimage.rotate(np_stds[method].real, 270)))**2 + (np.flipud(dlp_std[30:330, 30:330]))**2)\n",
    "relative_uncertainty = num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "plt.plot(ra,dec,c='w',lw=1)\n",
    "plt.imshow(relative_uncertainty,extent=get_extend_radec(resolution,  width))\n",
    "plt.colorbar()\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.title('Relative Uncertainty')\n",
    "plt.xticks(x_ticks)\n",
    "plt.yticks(y_ticks)\n",
    "plt.xlabel('Right Ascension')\n",
    "plt.ylabel('Declination')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('/share/gpu0/jjwhit/plots/final_2/rel_uq.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = relative_uncertainty.flatten()\n",
    "\n",
    "plt.hist(data_1d, bins=20, color='purple', edgecolor='black', density=True)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Relative Uncertainty')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('/share/gpu0/jjwhit/plots/final_2/rel_uq_hist.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical figure\n",
    "fig, axes = plt.subplots(3, 2, figsize=(7, 9), constrained_layout=True)\n",
    "\n",
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "im1 = axes[0, 0].imshow(rotated_img.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 0].plot(ra, dec, c='w', lw=1)\n",
    "axes[0, 0].set_title('GAN (Ours)')\n",
    "axes[0, 0].invert_xaxis()\n",
    "axes[0, 0].set_aspect('equal')\n",
    "axes[0, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 2: Deep Posterior\n",
    "axes[1, 0].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(cosmos_dlp_resized)\n",
    "im2 = axes[1, 0].imshow(flipped_img, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 0].set_title('Remy et al.')\n",
    "axes[1, 0].invert_xaxis()\n",
    "axes[1, 0].set_aspect('equal')\n",
    "axes[1, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 3: Kaiser-Squires\n",
    "axes[2, 0].plot(ra, dec, c='w', lw=1)\n",
    "im3 = axes[2, 0].imshow(relative_uncertainty, cmap='plasma',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[2, 0].set_title('Relative Uncertainty')\n",
    "axes[2, 0].invert_xaxis()\n",
    "axes[2, 0].set_aspect('equal')\n",
    "axes[2, 0].set_xlabel('Right Ascension')\n",
    "axes[2, 0].set_ylabel('Declination')\n",
    "\n",
    "# Plot 4: GAN Uncertainty\n",
    "axes[0, 1].plot(ra, dec, c='w', lw=1)\n",
    "rotated_img = ndimage.rotate(np_stds[method], 270)\n",
    "im4 = axes[0, 1].imshow(rotated_img.real, cmap='viridis', vmin=np.min(np_stds[method]), vmax=np.max(np_stds[method]),\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 1].set_title('GAN Uncertainty (Ours)')\n",
    "axes[0, 1].invert_xaxis()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "# axes[0, 1].set_xlabel('Right Ascension')\n",
    "# axes[0, 1].set_ylabel('Declination')\n",
    "\n",
    "# Plot 5: Deep Posterior Uncertainty\n",
    "axes[1, 1].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(dlp_std[30:330, 30:330])\n",
    "im5 = axes[1, 1].imshow(flipped_img, cmap='viridis',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 1].set_title('Remy et al. Uncertainty')\n",
    "axes[1, 1].invert_xaxis()\n",
    "axes[1, 1].set_aspect('equal')\n",
    "axes[1, 1].set_xlabel('Right Ascension')\n",
    "\n",
    "axes[2, 1].axis('off')\n",
    "\n",
    "m500min=3\n",
    "zmin=0.1\n",
    "zmax=0.99\n",
    "highz = (xclusters[:, 6] >= zmin) & (xclusters[:, 6] <= zmax)\n",
    "for cluster in xclusters[highz]:\n",
    "    ra_cl, dec_cl, z_cl = cluster[1], cluster[2], cluster[6]\n",
    "    m500 = cluster[7]\n",
    "    if m500 > m500min:\n",
    "        axes[0,0].scatter(ra_cl, dec_cl, c='w', s=3)\n",
    "        axes[0,0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=8, c='w')\n",
    "        axes[1,0].scatter(ra_cl, dec_cl, c='w', s=3)\n",
    "        axes[1,0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=8, c='w')\n",
    "\n",
    "\n",
    "# Define the colorbars using make_axes_locatable\n",
    "divider1 = make_axes_locatable(axes[0, 0])\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar1 = fig.colorbar(im1, cax=cax1)\n",
    "divider2 = make_axes_locatable(axes[1,0])\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar2 = fig.colorbar(im2, cax=cax2)\n",
    "divider3 = make_axes_locatable(axes[2,0])\n",
    "cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar3 = fig.colorbar(im3, cax=cax3)\n",
    "divider4 = make_axes_locatable(axes[0, 1])\n",
    "cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar4 = fig.colorbar(im4, cax=cax4)\n",
    "divider5 = make_axes_locatable(axes[1,1])\n",
    "cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar5 = fig.colorbar(im5, cax=cax5)\n",
    "\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        \n",
    "# plt.show()\n",
    "plt.savefig('/share/gpu0/jjwhit/plots/final_2/cosmos_rel_uq_unbounded.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal figure\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7), constrained_layout=True)\n",
    "\n",
    "x_ticks = [150.8, 150.1, 149.4]\n",
    "y_ticks = [2.8, 2.4, 2.0, 1.6]\n",
    "\n",
    "rotated_img = ndimage.rotate(np_avgs[method], 270)\n",
    "im1 = axes[0, 0].imshow(rotated_img.real, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 0].plot(ra, dec, c='w', lw=1)\n",
    "axes[0, 0].set_title('GAN (Ours)')\n",
    "axes[0, 0].invert_xaxis()\n",
    "axes[0, 0].set_aspect('equal')\n",
    "axes[0, 0].set_ylabel('Declination')\n",
    "axes[0, 0].set_xlabel('Right Ascension')\n",
    "\n",
    "# Plot 2: Deep Posterior\n",
    "axes[1, 0].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(cosmos_dlp_resized)\n",
    "im2 = axes[1, 0].imshow(flipped_img, cmap='magma', vmin=vmin, vmax=vmax,\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 0].set_title('Remy et al.')\n",
    "axes[1, 0].invert_xaxis()\n",
    "axes[1, 0].set_aspect('equal')\n",
    "axes[1, 0].set_ylabel('Declination')\n",
    "axes[1, 0].set_xlabel('Right Ascension')\n",
    "\n",
    "# Relative Uncertainty\n",
    "axes[0, 2].plot(ra, dec, c='w', lw=1)\n",
    "im3 = axes[0, 2].imshow(relative_uncertainty, cmap='plasma',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 2].set_title('Relative Uncertainty')\n",
    "axes[0, 2].invert_xaxis()\n",
    "axes[0, 2].set_aspect('equal')\n",
    "axes[0, 2].set_xlabel('Right Ascension')\n",
    "axes[0, 2].set_ylabel('Declination')\n",
    "\n",
    "# Plot 4: GAN Uncertainty\n",
    "axes[0, 1].plot(ra, dec, c='w', lw=1)\n",
    "rotated_img = ndimage.rotate(np_stds[method], 270)\n",
    "im4 = axes[0, 1].imshow(rotated_img.real, cmap='viridis', vmin=np.min(dlp_std[30:330, 30:330]), vmax=np.max(dlp_std[30:330, 30:330]),\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[0, 1].set_title('GAN Uncertainty (Ours)')\n",
    "axes[0, 1].invert_xaxis()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "axes[0, 1].set_xlabel('Right Ascension')\n",
    "axes[0, 1].set_ylabel('Declination')\n",
    "\n",
    "# Plot 5: Deep Posterior Uncertainty\n",
    "axes[1, 1].plot(ra, dec, c='w', lw=1)\n",
    "flipped_img = np.flipud(dlp_std[30:330, 30:330])\n",
    "im5 = axes[1, 1].imshow(flipped_img, cmap='viridis',\n",
    "                        extent=get_extend_radec(resolution, width), aspect='auto')\n",
    "axes[1, 1].set_title('Remy et al. Uncertainty')\n",
    "axes[1, 1].invert_xaxis()\n",
    "axes[1, 1].set_aspect('equal')\n",
    "axes[1, 1].set_xlabel('Right Ascension')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "m500min=3\n",
    "zmin=0.1\n",
    "zmax=0.99\n",
    "highz = (xclusters[:, 6] >= zmin) & (xclusters[:, 6] <= zmax)\n",
    "for cluster in xclusters[highz]:\n",
    "    ra_cl, dec_cl, z_cl = cluster[1], cluster[2], cluster[6]\n",
    "    m500 = cluster[7]\n",
    "    if m500 > m500min:\n",
    "        axes[0,0].scatter(ra_cl, dec_cl, c='w', s=3)\n",
    "        axes[0,0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=9, c='w')\n",
    "        axes[1,0].scatter(ra_cl, dec_cl, c='w', s=3)\n",
    "        axes[1,0].text(ra_cl + 0.03, dec_cl + 0.02, \"{:.2f}\".format(z_cl), fontsize=9, c='w')\n",
    "\n",
    "\n",
    "# Define the colorbars using make_axes_locatable\n",
    "divider1 = make_axes_locatable(axes[0, 0])\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar1 = fig.colorbar(im1, cax=cax1)\n",
    "divider2 = make_axes_locatable(axes[1,0])\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar2 = fig.colorbar(im2, cax=cax2)\n",
    "divider3 = make_axes_locatable(axes[0, 2])\n",
    "cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar3 = fig.colorbar(im3, cax=cax3)\n",
    "divider4 = make_axes_locatable(axes[0, 1])\n",
    "cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar4 = fig.colorbar(im4, cax=cax4)\n",
    "divider5 = make_axes_locatable(axes[1,1])\n",
    "cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar5 = fig.colorbar(im5, cax=cax5)\n",
    "\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        \n",
    "# plt.show()\n",
    "plt.savefig('/share/gpu0/jjwhit/plots/final_2/cosmos_rel_horizontal.png', bbox_inches='tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
