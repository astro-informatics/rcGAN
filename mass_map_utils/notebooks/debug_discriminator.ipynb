{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271e3279-1bb9-4d93-bc30-67d91ad77dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/gpu0/jjwhit/rcGAN/fastmri/__init__.py:16: UserWarning: Could not retrieve fastmri version!\n",
      "  warnings.warn(\"Could not retrieve fastmri version!\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/share/gpu0/jjwhit/rcGAN/')\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from models.archs.mri.generator import UNetModel\n",
    "from models.archs.mri.discriminator import DiscriminatorModel\n",
    "from data.lightning.MassMappingDataModule import MMDataTransform\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import types\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d73a625-e97e-4087-aa61-3494c99f72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, batch_norm=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        if self.in_chans != self.out_chans:\n",
    "            self.out_chans = self.in_chans\n",
    "\n",
    "        # self.norm = nn.BatchNorm2d(self.out_chans)\n",
    "        self.conv_1_x_1 = nn.Conv2d(self.in_chans, self.out_chans, kernel_size=(1, 1))\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Conv2d(self.in_chans, self.out_chans, kernel_size=(3, 3), padding=1),\n",
    "            # nn.BatchNorm2d(self.out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Conv2d(self.in_chans, self.out_chans, kernel_size=(3, 3), padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        output = input\n",
    "\n",
    "        return self.layers(output) + self.conv_1_x_1(output)\n",
    "\n",
    "\n",
    "class FullDownBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Conv2d(self.in_chans, self.out_chans, kernel_size=(3, 3), padding=1),\n",
    "            nn.InstanceNorm2d(self.out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.downsample(input)  # self.resblock(self.downsample(input))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'AvgPool(in_chans={self.in_chans}, out_chans={self.out_chans}\\nResBlock(in_chans={self.out_chans}, out_chans={self.out_chans}'\n",
    "\n",
    "\n",
    "class DiscriminatorModel(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, z_location=None, model_type=None, mbsd=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = 2\n",
    "        self.z_location = z_location\n",
    "        self.model_type = model_type\n",
    "        self.mbsd = mbsd\n",
    "\n",
    "        # CHANGE BACK TO 16 FOR MORE\n",
    "        self.initial_layers = nn.Sequential(\n",
    "            nn.Conv2d(self.in_chans, 32, kernel_size=(3, 3), padding=1),  # 384x384\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "        self.encoder_layers += [FullDownBlock(32, 64)]  # 64x64\n",
    "        self.encoder_layers += [FullDownBlock(64, 128)]  # 32x32\n",
    "        self.encoder_layers += [FullDownBlock(128, 256)]  # 16x16\n",
    "        self.encoder_layers += [FullDownBlock(256, 512)]  # 8x8\n",
    "        self.encoder_layers += [FullDownBlock(512, 512)]  # 4x4\n",
    "        self.encoder_layers += [FullDownBlock(512, 512)]  # 2x2\n",
    "        self.encoder_layers += [FullDownBlock(512, 512)]\n",
    "        self.encoder_layers += [FullDownBlock(512, 512)]\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input, y):\n",
    "        output = torch.cat([input, y], dim=1)\n",
    "        print('input.shape: ', input.shape)\n",
    "        print('y.shape: ', y.shape)\n",
    "        print('output.shape: ', output.shape)\n",
    "        output = self.initial_layers(output)\n",
    "        print('output.shape: ', output.shape)\n",
    "        # Apply down-sampling layers\n",
    "        print('Inside layers' )\n",
    "        for layer in self.encoder_layers:\n",
    "            print('output.shape: ', output.shape)\n",
    "            output = layer(output)\n",
    "        print('BEfore DEnse' )\n",
    "        print('output.shape: ', output.shape)\n",
    "        return self.dense(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a4fbc5-0ce5-48fc-ab9f-fcc6fabdb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.zeros(size=(5, 2, 1024, 1024), device=device).type(torch.FloatTensor)\n",
    "y = torch.zeros(size=(5, 2, 1024, 1024), device=device).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ab2b811-0019-4a1e-b264-8213219a0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "discriminator = DiscriminatorModel(in_chans=4, out_chans=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3417abd6-f23a-465a-8b4a-1db22d492fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape:  torch.Size([5, 2, 1024, 1024])\n",
      "y.shape:  torch.Size([5, 2, 1024, 1024])\n",
      "output.shape:  torch.Size([5, 4, 1024, 1024])\n",
      "output.shape:  torch.Size([5, 32, 1024, 1024])\n",
      "Inside layers\n",
      "output.shape:  torch.Size([5, 32, 1024, 1024])\n",
      "output.shape:  torch.Size([5, 64, 512, 512])\n",
      "output.shape:  torch.Size([5, 128, 256, 256])\n",
      "output.shape:  torch.Size([5, 256, 128, 128])\n",
      "output.shape:  torch.Size([5, 512, 64, 64])\n",
      "output.shape:  torch.Size([5, 512, 32, 32])\n",
      "output.shape:  torch.Size([5, 512, 16, 16])\n",
      "output.shape:  torch.Size([5, 512, 8, 8])\n",
      "BEfore DEnse\n",
      "output.shape:  torch.Size([5, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_pred = discriminator(input=x, y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79864944-085d-45a3-ab6b-1dddf44e3be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1461],\n",
       "        [-0.1461],\n",
       "        [-0.1461],\n",
       "        [-0.1461],\n",
       "        [-0.1461]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e598f31-cff9-423f-92f3-b5d984a0d030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cGAN",
   "language": "python",
   "name": "cgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
