{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77179fd8-ce2d-4f1c-a0b5-d90bce056ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/share/gpu0/jjwhit/rcGAN/')\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from models.archs.mri.generator import UNetModel\n",
    "from models.archs.mri.discriminator import DiscriminatorModel\n",
    "from data.lightning.MassMappingDataModule import MMDataTransform\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import types\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b50fc372-87b5-435e-ab6b-d69b0cb9125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "examples_path = '/share/gpu0/jjwhit/mass_map_dataset/kappa20_debug/kappa_val/kappa_run_00971.npy' \n",
    "\n",
    "args = {}\n",
    "\n",
    "transform = MMDataTransform(args)\n",
    "\n",
    "data = np.load(examples_path, allow_pickle=True).astype(np.complex128)\n",
    "# Tranform data and generate observations\n",
    "data_transformed = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43413491-565c-4963-9e1a-aa7ec852f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y, x, mean, std = data_transformed\n",
    "\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32ed5d1f-a6d5-4f25-8d10-ce9026db87de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "503c7313-1988-465f-8bf5-8412aa8d8d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1024, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[None,:,:,:]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9e3026b-4499-4dc0-aa99-371682e7303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(num_vectors):\n",
    "    z = torch.randn(num_vectors, 2, 1024, 1024, device=device)\n",
    "    return z\n",
    "\n",
    "num_vectors = y.size(0)\n",
    "\n",
    "noise = get_noise(num_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5c510d-d0fb-45f5-beaf-bce09bc190be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = torch.cat([y, noise], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "928bef9f-ff0f-4ce6-8374-7687c2d5bc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da2f24f7-3afe-4313-bd7d-c9dc4475e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = gen_input.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "517c93c7-0acb-4a60-b33d-d4ab4b2ca8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.archs.mri.generator import UNetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b96a70b-50d4-4d9d-8f9c-4bcf0ad4b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 2 + 2\n",
    "out_chans = 2\n",
    "\n",
    "generator = UNetModel(\n",
    "    in_chans=in_chans,\n",
    "    out_chans=out_chans,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b26874dc-a7ab-49f1-9ab0-a18bc95ccdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = generator(gen_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a7d3dca-5db0-44b3-8602-06c40252ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1024, 1024])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc19363-fe1d-4686-a798-fc170c70f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_tensor = reformat(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e2c23-d5d5-4cbc-8228-4189521d8a45",
   "metadata": {},
   "source": [
    "## Readd_measures Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4d2b4-3f7f-48e2-a560-b98da6c917c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(self, samples):\n",
    "    reformatted_tensor = torch.zeros(size=(samples.size(0), 1, self.resolution, self.resolution, 2),\n",
    "                                     device=self.device)\n",
    "    #Takes values from samples and assigns to reformatted tensor\n",
    "    #assumption: 0:8 for real, 8:16 for complex, multiple elements bc multiple MRI slices?\n",
    "    reformatted_tensor[:, :, :, :, 0] = samples[:, 0, :, :]\n",
    "    reformatted_tensor[:, :, :, :, 1] = samples[:, 1, :, :]\n",
    "\n",
    "    return reformatted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1d0fe-9f93-44f0-aa50-1a1d15ab872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readd_measures(self, samples, measures):\n",
    "    reformatted_tensor = self.reformat(samples)\n",
    "    measures = fft2c_new(self.reformat(measures))\n",
    "    reconstructed_kspace = fft2c_new(reformatted_tensor)\n",
    "\n",
    "    # reconstructed_kspace = mask * measures + (1 - mask) * reconstructed_kspace\n",
    "\n",
    "    image = ifft2c_new(reconstructed_kspace)\n",
    "\n",
    "    output_im = torch.zeros(size=samples.shape, device=self.device)\n",
    "    output_im[:, 0, :, :] = image[:, :, :, :, 0]\n",
    "    output_im[:, 1, :, :] = image[:, :, :, :, 1]\n",
    "\n",
    "    return output_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffc67320-1d3c-4985-9759-579b3f9b81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_tensor = torch.zeros(size=(5, 1024, 1024, 2), device=device)\n",
    "\n",
    "ex_samples = torch.zeros(size=(5, 2, 1024, 1024), device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe15cb98-9f7d-4895-a46b-6034afd7ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ex_samples[:, 0, :, :].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbb7d6c4-ce17-49ad-a5d8-645f3b55530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reformatted_tensor[:, :, :, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3072a872-bcfd-4c1a-91cd-9a08e15eec39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 1024, 1024])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c614c0d-a200-4483-802f-d95fea1c81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(ex_samples, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c800f58-f6c4-443a-a984-e102fc68f213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4ca64-5204-4241-95a2-b9da49a31976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326aae0-9964-4f12-8a74-b970e2b8aa31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cGAN",
   "language": "python",
   "name": "cgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
