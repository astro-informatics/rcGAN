{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fd3402-5307-4545-8f2b-96afb6e73b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jjwhit/rcGAN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5754d92b-cfe6-4399-963d-4203541616ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/fastmri/__init__.py:16: UserWarning: Could not retrieve fastmri version!\n",
      "  warnings.warn(\"Could not retrieve fastmri version!\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import types\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from data.lightning.MassMappingDataModule import MMDataModule\n",
    "from utils.parse_args import create_arg_parser\n",
    "from pytorch_lightning import seed_everything\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from utils.mri.math import tensor_to_complex_np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6282f5-ac84-45c2-911c-0c61e7d42f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model here\n",
    "test_plot_model = mmGAN.load_from_checkpoint('/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=88.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e69351c-c1a7-4037-af0f-2381edba6c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 1\n",
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")\n",
      "VALIDATING EPOCH: 71\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=70.ckpt'\n",
      "VALIDATING EPOCH: 72\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=71.ckpt'\n",
      "VALIDATING EPOCH: 73\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=72.ckpt'\n",
      "VALIDATING EPOCH: 74\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=73.ckpt'\n",
      "VALIDATING EPOCH: 75\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=74.ckpt'\n",
      "VALIDATING EPOCH: 76\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=75.ckpt'\n",
      "VALIDATING EPOCH: 77\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=76.ckpt'\n",
      "VALIDATING EPOCH: 78\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=77.ckpt'\n",
      "VALIDATING EPOCH: 79\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=78.ckpt'\n",
      "VALIDATING EPOCH: 80\n",
      "[Errno 2] No such file or directory: '/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3/checkpoint-epoch=79.ckpt'\n",
      "VALIDATING EPOCH: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   0%|          | 0/55 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/rcGAN/scripts/mass_map/validate.py:70\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     59\u001b[0m cfid_metric \u001b[38;5;241m=\u001b[39m CFIDMetric(\n\u001b[1;32m     60\u001b[0m     gan\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     61\u001b[0m     loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     num_samps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m cfids \u001b[38;5;241m=\u001b[39m \u001b[43mcfid_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cfid_torch_pinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m cfid_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cfids)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfid_val \u001b[38;5;241m<\u001b[39m best_cfid:\n",
      "File \u001b[0;32m~/rcGAN/evaluation_scripts/mass_map_cfid/cfid_metric.py:280\u001b[0m, in \u001b[0;36mCFIDMetric.get_cfid_torch_pinv\u001b[0;34m(self, resample, y_predict, x_true, y_true)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cfid_torch_pinv\u001b[39m(\u001b[38;5;28mself\u001b[39m, resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, y_predict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, x_true\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y_true\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_true \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m         y_predict, x_true, y_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_generated_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# mean estimations\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mto(x_true\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/rcGAN/evaluation_scripts/mass_map_cfid/cfid_metric.py:210\u001b[0m, in \u001b[0;36mCFIDMetric._get_generated_distribution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgan(condition)\n\u001b[1;32m    209\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embed_im(recon, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mkappa_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mkappa_std)\n\u001b[0;32m--> 210\u001b[0m condition_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_embed_im_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m true_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embed_im(gt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mkappa_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mkappa_std)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# WARNING -> transform()\u001b[39;00m\n",
      "File \u001b[0;32m~/rcGAN/evaluation_scripts/mass_map_cfid/cfid_metric.py:170\u001b[0m, in \u001b[0;36mCFIDMetric._get_embed_im_complex\u001b[0;34m(self, multi_coil_inp)\u001b[0m\n\u001b[1;32m    167\u001b[0m reformatted[:, :, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m multi_coil_inp[i, \u001b[38;5;241m0\u001b[39m, :, :]\n\u001b[1;32m    168\u001b[0m reformatted[:, :, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m multi_coil_inp[i, \u001b[38;5;241m1\u001b[39m, :, :]\n\u001b[0;32m--> 170\u001b[0m unnormal_im \u001b[38;5;241m=\u001b[39m \u001b[43munnormalize_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreformatted\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Mean/std calculated during preprocessing\u001b[39;00m\n\u001b[1;32m    172\u001b[0m im \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreal(torch\u001b[38;5;241m.\u001b[39mtensor(tensor_to_complex_np(unnormal_im\u001b[38;5;241m.\u001b[39mcpu())))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    173\u001b[0m im \u001b[38;5;241m=\u001b[39m (im \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(im)) \u001b[38;5;241m/\u001b[39m (torch\u001b[38;5;241m.\u001b[39mmax(im) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(im))\n",
      "File \u001b[0;32m~/rcGAN/utils/mri/transforms.py:280\u001b[0m, in \u001b[0;36munnormalize_complex\u001b[0;34m(normed_data, mag_mean, mag_std)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munnormalize_complex\u001b[39m(\n\u001b[1;32m    276\u001b[0m     normed_data: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m    277\u001b[0m     mag_mean: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.14049194898307577\u001b[39m, \n\u001b[1;32m    278\u001b[0m     mag_std: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.11606233247891737\u001b[39m,\n\u001b[1;32m    279\u001b[0m ):\n\u001b[0;32m--> 280\u001b[0m     normed_mag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mcomplex(normed_data[\u001b[38;5;241m0\u001b[39m,:,:], \u001b[43mnormed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    281\u001b[0m     phase \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mangle(torch\u001b[38;5;241m.\u001b[39mcomplex(normed_data[\u001b[38;5;241m0\u001b[39m,:,:], normed_data[\u001b[38;5;241m1\u001b[39m,:,:]))\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# mag_data = ((normed_data * mag_std) / torch.exp(1j*phase)) + mag_mean\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# unnormed_data_real = mag_data * torch.cos(phase)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# unnormed_data_imag = mag_data * torch.sin(phase)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "%run /home/jjwhit/rcGAN/scripts/mass_map/validate.py --config /home/jjwhit/rcGAN/configs/mass_map_test.yml --exp-name mmgan_training_3 --num-gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8241006-e939-42a6-b8ea-ad0a8bb6718b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae012947-1dc8-4e5a-b272-c6f0a804bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2955b4-8cb2-46fc-9f1a-ecea6a8eeffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8664928-725a-45b7-a6c1-3a02956e4504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7c18f1-4285-49ee-9c81-3b3b54629cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 1\n",
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n",
      "\n",
      "\n",
      "1 SAMPLES\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2863, in safe_execfile\n",
      "    py3compat.execfile(\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/utils/py3compat.py\", line 55, in execfile\n",
      "    exec(compiler(f.read(), fname, \"exec\"), glob, loc)\n",
      "  File \"/home/jjwhit/rcGAN/scripts/mass_map/test.py\", line 118, in <module>\n",
      "    distss.append(dists_met(rgb(gt_np, unit_norm=True), rgb(avg_gen_np, unit_norm=True)).numpy())\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/DISTS_pytorch/DISTS_pt.py\", line 88, in forward\n",
      "    feats1 = self.forward_once(y)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/DISTS_pytorch/DISTS_pt.py\", line 73, in forward_once\n",
      "    h = self.stage3(h)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "%run /home/jjwhit/rcGAN/scripts/mass_map/test.py --exp-name mmgan_training_8 --num-figs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a05c46-25a9-40a0-8862-786d96086a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ba34a-f091-4c9e-b076-6dafd025cdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e7976-ef57-456d-b449-5e48d65f85cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15f9ba-e560-4b33-9a06-74ad2f91dba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13918633-383c-4434-bdbe-8b8a8489af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92cb27-b494-4868-a65f-d049641cc8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b7dedc-a033-44d8-90ee-20f1a70138c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/fastmri/__init__.py:16: UserWarning: Could not retrieve fastmri version!\n",
      "  warnings.warn(\"Could not retrieve fastmri version!\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import types\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "dir = '/home/jjwhit/rcGAN/'\n",
    "sys.path.append(dir)\n",
    "\n",
    "from data.lightning.MassMappingDataModule import MMDataModule\n",
    "from utils.parse_args import create_arg_parser\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from pytorch_lightning import seed_everything\n",
    "from utils.embeddings import VGG16Embedding\n",
    "from evaluation_scripts.mass_map_cfid.cfid_metric import CFIDMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11d5926-07aa-458f-a276-31df96ee8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cb73a8-f961-4df3-bc98-ff529a3a72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(dct):\n",
    "    return types.SimpleNamespace(**dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbe128c-354f-4087-949f-81dfc2c80da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "# seed_everything(1, workers=True)\n",
    "\n",
    "with open(dir+'configs/mass_map.yml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    cfg = json.loads(json.dumps(cfg), object_hook=load_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6bf929-e2e0-4144-a2d0-8735c558368d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dm = MMDataModule(cfg)\n",
    "dm.setup()\n",
    "val_loader = dm.val_dataloader()\n",
    "best_epoch = -1\n",
    "inception_embedding = VGG16Embedding()\n",
    "best_cfid = 10000000\n",
    "start_epoch = 80 #Will start saving models after 70 epochs\n",
    "end_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac110024-0d5e-4476-b0d6-b44c837ad145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATING EPOCH: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   2%|▏         | 1/55 [00:03<03:35,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   5%|▌         | 3/55 [00:04<00:57,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   7%|▋         | 4/55 [00:04<00:38,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   9%|▉         | 5/55 [00:05<00:30,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n",
      "torch.Size([1, 300, 300, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:  11%|█         | 6/55 [00:05<00:22,  2.14it/s]"
     ]
    }
   ],
   "source": [
    "    with torch.no_grad():\n",
    "        \n",
    "        for epoch in range(start_epoch, end_epoch):\n",
    "            print(f\"VALIDATING EPOCH: {epoch}\")\n",
    "            try:\n",
    "                model = mmGAN.load_from_checkpoint(checkpoint_path='/share/gpu0/jjwhit/mass_map/mm_models/mmgan_training_3' + f'/checkpoint-epoch={epoch}.ckpt')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            if model.is_good_model == 0:\n",
    "                print(\"NO GOOD: SKIPPING...\")\n",
    "                continue\n",
    "\n",
    "            model = model.cuda()\n",
    "            model.eval()\n",
    "\n",
    "            cfid_metric = CFIDMetric(\n",
    "                gan=model,\n",
    "                loader=val_loader,\n",
    "                image_embedding=inception_embedding,\n",
    "                condition_embedding=inception_embedding,\n",
    "                cuda=True,\n",
    "                args=cfg,\n",
    "                ref_loader=False,\n",
    "                num_samps=1\n",
    "            )\n",
    "\n",
    "            cfids = cfid_metric.get_cfid_torch_pinv()\n",
    "\n",
    "            cfid_val = np.mean(cfids)\n",
    "\n",
    "            if cfid_val < best_cfid:\n",
    "                best_epoch = epoch\n",
    "                best_cfid = cfid_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bec8f0-46bc-46fe-8d35-e9827cc9eb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cGAN",
   "language": "python",
   "name": "cgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
